{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde84abf",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸŒ¾ CSIRO Image2Biomass Prediction - Kaggle Competition\n",
    "\n",
    "**Author:** Manish Kumar Singh  \n",
    "**Competition:** [CSIRO - Image2Biomass Prediction](https://www.kaggle.com/competitions/csiro-biomass)  \n",
    "**Objective:** Predict pasture biomass from drone and ground images using deep learning.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Table of Contents\n",
    "1. Introduction  \n",
    "2. Imports & Setup  \n",
    "3. Data Loading and Exploration  \n",
    "4. Image Visualization  \n",
    "5. Data Preprocessing  \n",
    "6. Custom Weighted RÂ² Metric  \n",
    "7. Model Architecture (EfficientNetB0)  \n",
    "8. Training Configuration and Callbacks  \n",
    "9. Model Training  \n",
    "10. Model Evaluation  \n",
    "11. Inference and Submission Creation  \n",
    "12. Visualization: Predictions vs Ground Truth  \n",
    "13. Final Results and Insights  \n",
    "14. Appendix and References  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb033235",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Introduction\n",
    "\n",
    "The **CSIRO Image2Biomass Prediction** competition challenges participants to estimate pasture biomass using drone and ground imagery.  \n",
    "Accurate predictions help improve **farm efficiency**, **animal welfare**, and **soil sustainability**.\n",
    "\n",
    "### Evaluation Metric: Weighted RÂ²\n",
    "The competition uses a weighted version of the RÂ² (coefficient of determination):\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum w_i(y_i - \\hat{y}_i)^2}{\\sum w_i(y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "| Target | Weight |\n",
    "|---------|---------|\n",
    "| Dry_Green_g | 0.1 |\n",
    "| Dry_Dead_g | 0.1 |\n",
    "| Dry_Clover_g | 0.1 |\n",
    "| GDM_g | 0.2 |\n",
    "| Dry_Total_g | 0.5 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b09d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, cv2, random, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(f\"âœ… TensorFlow {tf.__version__} | NumPy {np.__version__} | Pandas {pd.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce9db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = '/kaggle/input/csiro-biomass'\n",
    "train_df = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n",
    "test_df = pd.read_csv(f\"{DATA_PATH}/test.csv\")\n",
    "sample_submission = pd.read_csv(f\"{DATA_PATH}/sample_submission.csv\")\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e511a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def visualize_samples(df, img_dir, num=6):\n",
    "    sample = df.sample(num, random_state=SEED)\n",
    "    plt.figure(figsize=(15,6))\n",
    "    for i, row in enumerate(sample.itertuples()):\n",
    "        path = os.path.join(img_dir, f\"{row.image_id}.jpg\")\n",
    "        img = mpimg.imread(path)\n",
    "        plt.subplot(2, num//2, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{row.image_id}\\nBiomass: {getattr(row, 'biomass', 'NA'):.2f}\" if 'biomass' in df.columns else row.image_id)\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(\"Sample Training Images\", fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples(train_df, f\"{DATA_PATH}/train_images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e1327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "train_data, val_data = train_test_split(train_df, test_size=VAL_SPLIT, random_state=SEED)\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_flow = train_gen.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    directory=f\"{DATA_PATH}/train_images\",\n",
    "    x_col='image_id',\n",
    "    y_col='biomass',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    class_mode='raw',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_flow = val_gen.flow_from_dataframe(\n",
    "    dataframe=val_data,\n",
    "    directory=f\"{DATA_PATH}/train_images\",\n",
    "    x_col='image_id',\n",
    "    y_col='biomass',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    class_mode='raw',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e522cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weighted_r2(y_true, y_pred, weights=None):\n",
    "    if weights is None:\n",
    "        weights = np.ones_like(y_true)\n",
    "    y_true_mean = np.average(y_true, weights=weights)\n",
    "    ss_res = np.sum(weights * (y_true - y_pred)**2)\n",
    "    ss_tot = np.sum(weights * (y_true - y_true_mean)**2)\n",
    "    return 1 - ss_res / (ss_tot + 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7095ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(input_shape=(224,224,3)):\n",
    "    base = EfficientNetB0(include_top=False, input_shape=input_shape, weights='imagenet')\n",
    "    base.trainable = False\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(1, activation='linear')(x)\n",
    "    model = models.Model(inputs=base.input, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de531428",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3),\n",
    "    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_flow,\n",
    "    validation_data=val_flow,\n",
    "    epochs=25,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Val')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e5ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_flow = test_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=f\"{DATA_PATH}/test_images\",\n",
    "    x_col='image_id',\n",
    "    y_col=None,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    class_mode=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "preds = model.predict(test_flow)\n",
    "submission = pd.DataFrame({\n",
    "    'sample_id': sample_submission['sample_id'],\n",
    "    'target': preds.flatten()\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"âœ… Submission file created: submission.csv\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
