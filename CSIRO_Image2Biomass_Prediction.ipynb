{\n "cells": [\n {\n "cell_type": "markdown",\n "metadata": {},\n "source": [\n "# Competition Title \n \n [Link to Competition](https://www.kaggle.com/competitions/csiro-biomass) \n ",\n "# Author: Manish Kumar Singh \n # Date: 2025-11-08"\n ]\n },\n {\n "cell_type": "code",\n "execution_count": null,\n "metadata": {},\n "outputs": [],\n "source": [\n "# Stage 1: Data Loading & Preprocessing\n import pandas as pd\n import numpy as np\n from sklearn.model_selection import train_test_split\n from keras.preprocessing.image import ImageDataGenerator\n \n # Load Data\n data_path = '/kaggle/input/csiro-biomass'\n # Assume there are CSVs or DataFrames to load\n data = pd.read_csv(f'{data_path}/data.csv')\n \n # Handling Missing Values\n data.fillna(data.mean(), inplace=True)\n \n # Log Transformation\n data['log_column'] = np.log1p(data['column'])\n \n # Train/Validation Split\n train_df, val_df = train_test_split(data, test_size=0.2, random_state=42)\n \n # Data Generators\n train_datagen = ImageDataGenerator(rescale=1./255)\n val_datagen = ImageDataGenerator(rescale=1./255)\n train_generator = train_datagen.flow_from_dataframe(train_df, target_size=(224, 224), batch_size=32, class_mode='binary')\n val_generator = val_datagen.flow_from_dataframe(val_df, target_size=(224, 224), batch_size=32, class_mode='binary')\n "\n ]\n },\n {\n "cell_type": "code",\n "execution_count": null,\n "metadata": {},\n "outputs": [],\n "source": [\n "# Stage 2: Model Building\n from keras.applications import EfficientNetB0\n from keras.models import Sequential\n from keras.layers import Dense, GlobalAveragePooling2D\n \n model = Sequential()\n model.add(EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3)))\n model.add(GlobalAveragePooling2D())\n model.add(Dense(1, activation='sigmoid'))\n model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n "\n ]\n },\n {\n "cell_type": "code",\n "execution_count": null,\n "metadata": {},\n "outputs": [],\n "source": [\n "# Stage 3: Training & Evaluation\n from keras.callbacks import EarlyStopping, ModelCheckpoint\n \n callbacks = [\n EarlyStopping(patience=10),\n ModelCheckpoint('model.h5', save_best_only=True)\n ]\n \n history = model.fit(train_generator, validation_data=val_generator, epochs=50, callbacks=callbacks)\n "\n ]\n },\n {\n "cell_type": "code",\n "execution_count": null,\n "metadata": {},\n "outputs": [],\n "source": [\n "# Stage 4: Weighted R² Metric\n from keras import backend as K\n \n def weighted_r2(y_true, y_pred):\n     weights = { 'Dry_Green_g': 0.1, 'Dry_Dead_g': 0.1, 'Dry_Clover_g': 0.1, 'GDM_g': 0.2, 'Dry_Total_g': 0.5 }\n     # Calculate the weighted R² Metric... \n     return r2_score \n "\n ]\n },\n {\n "cell_type": "code",\n "execution_count": null,\n "metadata": {},\n "outputs": [],\n "source": [\n "# Stage 5: Inference & Submission\n predictions = model.predict(val_generator)\n submission = pd.DataFrame({'Id': val_df['id'], 'Prediction': predictions.flatten()})\n submission.to_csv('submission.csv', index=False)\n "\n ]\n },\n {\n "cell_type": "code",\n "execution_count": null,\n "metadata": {},\n "outputs": [],\n "source": [\n "# Stage 6: Visualization\n import matplotlib.pyplot as plt\n \n plt.plot(history.history['loss'], label='train_loss')\n plt.plot(history.history['val_loss'], label='val_loss')\n plt.title('Loss Curves')\n plt.xlabel('Epochs')\n plt.ylabel('Loss')\n plt.legend()\n plt.show()\n "\n ]\n },\n {\n "cell_type": "markdown",\n "metadata": {},\n "source": [\n "# Stage 7: Final Summary \n In this notebook, we've... \n "\n ]\n },\n {\n "cell_type": "markdown",\n "metadata": {},\n "source": [\n "# Stage 8: Appendix \n Additional information about the methods... \n "\n ]\n }\n ],\n "metadata": {\n "kernelspec": {\n "display_name": "Python 3",\n "language": "python",\n "name": "python3"\n },\n "language_info": {\n "codemirror_mode": {\n "name": "ipython3"\n },\n "file_extension": ".ipynb",\n "mimetype": "text/x-ipynb+json",\n "name": "ipython",\n "nbconvert_exporter": "python","pygments_lexer": "ipython3","version": "3.8.5"\n },\n "nbformat": 4,\n "nbformat_minor": 2\n }\n}